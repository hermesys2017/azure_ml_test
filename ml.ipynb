{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.get(name='mlw-dp100-labs',\n",
    "                   subscription_id='b4ad3633-b1bc-4093-bcd2-00ce43cc11b1',\n",
    "                   resource_group='rg-dp100-labs'\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for compute_name in ws.compute_targets:\n",
    "    compute = ws.compute_targets[compute_name]\n",
    "    print(compute.name, \":\", compute.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "# create an experiment variable\n",
    "experiment = Experiment(workspace = ws, name = \"my-experiment\")\n",
    "\n",
    "# start the experiment\n",
    "run = experiment.start_logging()\n",
    "\n",
    "# experiment code goes here\n",
    "\n",
    "\n",
    "# end the experiment\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/02/07 12:02:10 INFO mlflow.tracking.fluent: Experiment with name 'mlflow-experiment' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "# MLFlow 샘플\n",
    "\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n",
    "# Set the experiment\n",
    "mlflow.set_experiment(\"mlflow-experiment\")\n",
    "\n",
    "# Start the run\n",
    "mlflow_run = mlflow.start_run()\n",
    "# Log metrics or other information\n",
    "mlflow.log_metric('mymetric', 1)\n",
    "# End run \n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workspacefilestore\n",
      "workspaceblobstore\n",
      "workspaceworkingdirectory\n",
      "workspaceartifactstore\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace, Datastore\n",
    "\n",
    "# Register a new datastore\n",
    "for ds_name in ws.datastores:\n",
    "    print(ds_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_store = Datastore.get(ws, datastore_name='workspaceblobstore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-07 05:58:55.141732 | ActivityCompleted: Activity=from_delimited_files, HowEnded=Failure, Duration=833.4 [ms], Info = {'activity_id': '744f8b13-cd33-45e1-85ef-22479cee6be6', 'activity_name': 'from_delimited_files', 'activity_type': 'PublicApi', 'app_name': 'TabularDataset', 'source': 'azureml.dataset', 'version': '1.48.0', 'dataprepVersion': '4.8.6', 'sparkVersion': '', 'subscription': '', 'run_id': '', 'resource_group': '', 'workspace_name': '', 'experiment_id': '', 'location': ''}, Exception=NotImplementedError; Linux distribution ubuntu 22.04 does not have automatic support. \n",
      "Missing packages: {'liblttng-ust.so.0'}\n",
      ".NET Core 3.1 can still be used via `dotnetcore2` if the required dependencies are installed.\n",
      "Visit https://aka.ms/dotnet-install-linux for Linux distro specific .NET Core install instructions.\n",
      "Follow your distro specific instructions to install `dotnet-runtime-*` and replace `*` with `3.1.23`.\n",
      "\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Linux distribution ubuntu 22.04 does not have automatic support. \nMissing packages: {'liblttng-ust.so.0'}\n.NET Core 3.1 can still be used via `dotnetcore2` if the required dependencies are installed.\nVisit https://aka.ms/dotnet-install-linux for Linux distro specific .NET Core install instructions.\nFollow your distro specific instructions to install `dotnet-runtime-*` and replace `*` with `3.1.23`.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/workspaces/azure_ml_test/venv/lib/python3.10/site-packages/dotnetcore2/runtime.py:271\u001b[0m, in \u001b[0;36mensure_dependencies.<locals>.attempt_get_deps\u001b[0;34m(missing_pkgs)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 271\u001b[0m     blob_deps_to_file()\n\u001b[1;32m    272\u001b[0m     success \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/workspaces/azure_ml_test/venv/lib/python3.10/site-packages/dotnetcore2/runtime.py:263\u001b[0m, in \u001b[0;36mensure_dependencies.<locals>.blob_deps_to_file\u001b[0;34m()\u001b[0m\n\u001b[1;32m    262\u001b[0m ssl_context \u001b[39m=\u001b[39m ssl\u001b[39m.\u001b[39mcreate_default_context(cafile\u001b[39m=\u001b[39mcafile)\n\u001b[0;32m--> 263\u001b[0m blob \u001b[39m=\u001b[39m request\u001b[39m.\u001b[39;49murlopen(deps_url, context\u001b[39m=\u001b[39;49mssl_context)\n\u001b[1;32m    264\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(deps_tar_path, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n",
      "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    215\u001b[0m     opener \u001b[39m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[39mreturn\u001b[39;00m opener\u001b[39m.\u001b[39;49mopen(url, data, timeout)\n",
      "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    524\u001b[0m     meth \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 525\u001b[0m     response \u001b[39m=\u001b[39m meth(req, response)\n\u001b[1;32m    527\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m code \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m):\n\u001b[0;32m--> 634\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparent\u001b[39m.\u001b[39;49merror(\n\u001b[1;32m    635\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mhttp\u001b[39;49m\u001b[39m'\u001b[39;49m, request, response, code, msg, hdrs)\n\u001b[1;32m    637\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    562\u001b[0m args \u001b[39m=\u001b[39m (\u001b[39mdict\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhttp_error_default\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m+\u001b[39m orig_args\n\u001b[0;32m--> 563\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_chain(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    495\u001b[0m func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    497\u001b[0m \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhttp_error_default\u001b[39m(\u001b[39mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 643\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(req\u001b[39m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mazureml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m Dataset\n\u001b[1;32m      3\u001b[0m csv_path \u001b[39m=\u001b[39m [(blob_store, \u001b[39m'\u001b[39m\u001b[39m./data/train.csv\u001b[39m\u001b[39m'\u001b[39m), (blob_store, \u001b[39m'\u001b[39m\u001b[39m./data/test.csv\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[0;32m----> 4\u001b[0m tab_ds \u001b[39m=\u001b[39m Dataset\u001b[39m.\u001b[39;49mTabular\u001b[39m.\u001b[39;49mfrom_delimited_files(path\u001b[39m=\u001b[39;49mcsv_path)\n\u001b[1;32m      5\u001b[0m tab_ds \u001b[39m=\u001b[39m tab_ds\u001b[39m.\u001b[39mregister(workspace\u001b[39m=\u001b[39mws, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msample_data\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/workspaces/azure_ml_test/venv/lib/python3.10/site-packages/azureml/data/_loggerfactory.py:132\u001b[0m, in \u001b[0;36mtrack.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39mwith\u001b[39;00m _LoggerFactory\u001b[39m.\u001b[39mtrack_activity(logger, func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, activity_type, custom_dimensions) \u001b[39mas\u001b[39;00m al:\n\u001b[1;32m    131\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 132\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    133\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    134\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(al, \u001b[39m'\u001b[39m\u001b[39mactivity_info\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39merror_code\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/workspaces/azure_ml_test/venv/lib/python3.10/site-packages/azureml/data/dataset_factory.py:357\u001b[0m, in \u001b[0;36mTabularDatasetFactory.from_delimited_files\u001b[0;34m(path, validate, include_path, infer_column_types, set_column_types, separator, header, partition_format, support_multi_line, empty_as_string, encoding)\u001b[0m\n\u001b[1;32m    347\u001b[0m     dataflow \u001b[39m=\u001b[39m dataprep()\u001b[39m.\u001b[39mread_csv(path,\n\u001b[1;32m    348\u001b[0m                                    verify_exists\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    349\u001b[0m                                    include_path\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    354\u001b[0m                                    empty_as_string\u001b[39m=\u001b[39mempty_as_string,\n\u001b[1;32m    355\u001b[0m                                    encoding\u001b[39m=\u001b[39mencoding)\n\u001b[1;32m    356\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 357\u001b[0m     dataflow \u001b[39m=\u001b[39m dataprep()\u001b[39m.\u001b[39;49mread_csv(path,\n\u001b[1;32m    358\u001b[0m                                    verify_exists\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    359\u001b[0m                                    include_path\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    360\u001b[0m                                    infer_column_types\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    361\u001b[0m                                    separator\u001b[39m=\u001b[39;49mseparator,\n\u001b[1;32m    362\u001b[0m                                    header\u001b[39m=\u001b[39;49mheader,\n\u001b[1;32m    363\u001b[0m                                    quoting\u001b[39m=\u001b[39;49msupport_multi_line,\n\u001b[1;32m    364\u001b[0m                                    encoding\u001b[39m=\u001b[39;49mencoding)\n\u001b[1;32m    366\u001b[0m dataflow \u001b[39m=\u001b[39m _transform_and_validate(\n\u001b[1;32m    367\u001b[0m     dataflow, partition_format, include_path,\n\u001b[1;32m    368\u001b[0m     validate,\n\u001b[1;32m    369\u001b[0m     infer_column_types \u001b[39mor\u001b[39;00m _is_inference_required(set_column_types))\n\u001b[1;32m    370\u001b[0m \u001b[39mif\u001b[39;00m infer_column_types:\n",
      "File \u001b[0;32m~/workspaces/azure_ml_test/venv/lib/python3.10/site-packages/azureml/dataprep/api/readers.py:100\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(path, separator, header, encoding, quoting, inference_arguments, skip_rows, skip_mode, comment, include_path, archive_options, infer_column_types, verify_exists, partition_size, empty_as_string)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mCreates a new Dataflow with the operations required to read CSV and other delimited text files (TSV, custom delimiters like semicolon, colon etc.).\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[39m:return: A new Dataflow.\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m skip_mode \u001b[39m=\u001b[39m _default_skip_mode(skip_mode, skip_rows)\n\u001b[0;32m--> 100\u001b[0m df \u001b[39m=\u001b[39m Dataflow\u001b[39m.\u001b[39;49m_path_to_get_files_block(path, archive_options)\n\u001b[1;32m    101\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mparse_delimited(separator, header, encoding, quoting, skip_rows, skip_mode, comment, partition_size, empty_as_string)\n\u001b[1;32m    103\u001b[0m df \u001b[39m=\u001b[39m _handle_type_inference_and_path(df, inference_arguments, infer_column_types, include_path)\n",
      "File \u001b[0;32m~/workspaces/azure_ml_test/venv/lib/python3.10/site-packages/azureml/dataprep/api/dataflow.py:2427\u001b[0m, in \u001b[0;36mDataflow._path_to_get_files_block\u001b[0;34m(path, archive_options)\u001b[0m\n\u001b[1;32m   2425\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   2426\u001b[0m     \u001b[39mif\u001b[39;00m _is_datapath(path) \u001b[39mor\u001b[39;00m _is_datapaths(path):\n\u001b[0;32m-> 2427\u001b[0m         \u001b[39mreturn\u001b[39;00m datastore_to_dataflow(path)\n\u001b[1;32m   2428\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m   2429\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/workspaces/azure_ml_test/venv/lib/python3.10/site-packages/azureml/dataprep/api/_datastore_helper.py:39\u001b[0m, in \u001b[0;36mdatastore_to_dataflow\u001b[0;34m(data_source, query_timeout, is_file)\u001b[0m\n\u001b[1;32m     37\u001b[0m datastore_values \u001b[39m=\u001b[39m []\n\u001b[1;32m     38\u001b[0m \u001b[39mfor\u001b[39;00m source \u001b[39min\u001b[39;00m data_source:\n\u001b[0;32m---> 39\u001b[0m     datastore, datastore_value \u001b[39m=\u001b[39m get_datastore_value(source)\n\u001b[1;32m     40\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_fs_datastore(datastore):\n\u001b[1;32m     41\u001b[0m         \u001b[39mraise\u001b[39;00m NotSupportedDatastoreTypeError(datastore)\n",
      "File \u001b[0;32m~/workspaces/azure_ml_test/venv/lib/python3.10/site-packages/azureml/dataprep/api/_datastore_helper.py:91\u001b[0m, in \u001b[0;36mget_datastore_value\u001b[0;34m(data_source)\u001b[0m\n\u001b[1;32m     88\u001b[0m _ensure_supported(datastore)\n\u001b[1;32m     90\u001b[0m workspace \u001b[39m=\u001b[39m datastore\u001b[39m.\u001b[39mworkspace\n\u001b[0;32m---> 91\u001b[0m _set_auth_type(workspace)\n\u001b[1;32m     92\u001b[0m \u001b[39mreturn\u001b[39;00m (datastore, DatastoreValue(\n\u001b[1;32m     93\u001b[0m     subscription\u001b[39m=\u001b[39mworkspace\u001b[39m.\u001b[39msubscription_id,\n\u001b[1;32m     94\u001b[0m     resource_group\u001b[39m=\u001b[39mworkspace\u001b[39m.\u001b[39mresource_group,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     97\u001b[0m     path\u001b[39m=\u001b[39mpath_on_storage\n\u001b[1;32m     98\u001b[0m ))\n",
      "File \u001b[0;32m~/workspaces/azure_ml_test/venv/lib/python3.10/site-packages/azureml/dataprep/api/_datastore_helper.py:177\u001b[0m, in \u001b[0;36m_set_auth_type\u001b[0;34m(workspace)\u001b[0m\n\u001b[1;32m    174\u001b[0m     auth_type \u001b[39m=\u001b[39m AuthType\u001b[39m.\u001b[39mDERIVED\n\u001b[1;32m    176\u001b[0m auth_value \u001b[39m=\u001b[39m auth\n\u001b[0;32m--> 177\u001b[0m get_engine_api()\u001b[39m.\u001b[39mset_aml_auth(SetAmlAuthMessageArgument(auth_type, json\u001b[39m.\u001b[39mdumps(auth_value)))\n",
      "File \u001b[0;32m~/workspaces/azure_ml_test/venv/lib/python3.10/site-packages/azureml/dataprep/api/engineapi/api.py:19\u001b[0m, in \u001b[0;36mget_engine_api\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mglobal\u001b[39;00m _engine_api\n\u001b[1;32m     18\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _engine_api:\n\u001b[0;32m---> 19\u001b[0m     _engine_api \u001b[39m=\u001b[39m EngineAPI()\n\u001b[1;32m     21\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_dataset_resolver\u001b[39;00m \u001b[39mimport\u001b[39;00m register_dataset_resolver\n\u001b[1;32m     22\u001b[0m     register_dataset_resolver(_engine_api\u001b[39m.\u001b[39mrequests_channel)\n",
      "File \u001b[0;32m~/workspaces/azure_ml_test/venv/lib/python3.10/site-packages/azureml/dataprep/api/engineapi/api.py:102\u001b[0m, in \u001b[0;36mEngineAPI.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine_server_secret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msync_host_secret(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequests_channel\u001b[39m.\u001b[39mhost_secret)\n\u001b[1;32m    100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine_server_port \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msync_host_channel_port(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequests_channel\u001b[39m.\u001b[39mport)\n\u001b[0;32m--> 102\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_message_channel \u001b[39m=\u001b[39m launch_engine()\n\u001b[1;32m    103\u001b[0m connect_to_requests_channel()\n\u001b[1;32m    105\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_message_channel\u001b[39m.\u001b[39mon_relaunch(connect_to_requests_channel)\n",
      "File \u001b[0;32m~/workspaces/azure_ml_test/venv/lib/python3.10/site-packages/azureml/dataprep/api/engineapi/engine.py:333\u001b[0m, in \u001b[0;36mlaunch_engine\u001b[0;34m()\u001b[0m\n\u001b[1;32m    331\u001b[0m engine_path \u001b[39m=\u001b[39m _get_engine_path()\n\u001b[1;32m    332\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 333\u001b[0m     dependencies_path \u001b[39m=\u001b[39m runtime\u001b[39m.\u001b[39;49mensure_dependencies()\n\u001b[1;32m    334\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    335\u001b[0m     _LoggerFactory\u001b[39m.\u001b[39mtrace(log, \u001b[39m'\u001b[39m\u001b[39mFailed to ensure dependencies\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e))\n",
      "File \u001b[0;32m~/workspaces/azure_ml_test/venv/lib/python3.10/site-packages/dotnetcore2/runtime.py:285\u001b[0m, in \u001b[0;36mensure_dependencies\u001b[0;34m()\u001b[0m\n\u001b[1;32m    282\u001b[0m         success \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    283\u001b[0m     \u001b[39mreturn\u001b[39;00m success\n\u001b[0;32m--> 285\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m attempt_get_deps(missing_pkgs):\n\u001b[1;32m    286\u001b[0m     \u001b[39m# Failed accessing blob, likely an interrupted connection. Try again once more.\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m attempt_get_deps(missing_pkgs):\n\u001b[1;32m    288\u001b[0m         err_msg \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mUnable to retrieve .NET dependencies. Please make sure you are connected to the Internet and have \u001b[39m\u001b[39m\\\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[39m            a stable network connection. \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mMissing packages: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(missing_pkgs, _unsupported_help_msg)\n",
      "File \u001b[0;32m~/workspaces/azure_ml_test/venv/lib/python3.10/site-packages/dotnetcore2/runtime.py:279\u001b[0m, in \u001b[0;36mensure_dependencies.<locals>.attempt_get_deps\u001b[0;34m(missing_pkgs)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[39mif\u001b[39;00m e\u001b[39m.\u001b[39mcode \u001b[39m==\u001b[39m \u001b[39m404\u001b[39m:\n\u001b[1;32m    276\u001b[0m         \u001b[39m# Requested blob not found so we don't have deps for this distribution.\u001b[39;00m\n\u001b[1;32m    277\u001b[0m         err_msg \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mLinux distribution \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m does not have automatic support. \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mMissing packages: \u001b[39m\u001b[39m{3}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    278\u001b[0m             dist, version[\u001b[39m0\u001b[39m], version[\u001b[39m1\u001b[39m], missing_pkgs)\n\u001b[0;32m--> 279\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(err_msg \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m _unsupported_help_msg)\n\u001b[1;32m    280\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    281\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mException when accessing blob: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e))\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Linux distribution ubuntu 22.04 does not have automatic support. \nMissing packages: {'liblttng-ust.so.0'}\n.NET Core 3.1 can still be used via `dotnetcore2` if the required dependencies are installed.\nVisit https://aka.ms/dotnet-install-linux for Linux distro specific .NET Core install instructions.\nFollow your distro specific instructions to install `dotnet-runtime-*` and replace `*` with `3.1.23`.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "csv_path = [(blob_store, './data/train.csv'), (blob_store, './data/test.csv')]\n",
    "tab_ds = Dataset.Tabular.from_delimited_files(path=csv_path)\n",
    "tab_ds = tab_ds.register(workspace=ws, name='sample_data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "044f471feba94080b3115585e3d012b03266d38e7e83cf164f3603e0c7c0ef49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
